import cv2
import numpy as np

# Load the images
img1 = cv2.imread(r"C:\Users\poornima\Downloads\im.jpeg")
img2 = cv2.imread(r"C:\Users\poornima\Downloads\IMG 2.jpeg")

# Convert the images to grayscale
gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

# Detect keypoints using SIFT
sift = cv2.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)

# Match keypoints using Brute-Force matcher
bf = cv2.BFMatcher(cv2.NORM_L2)
matches = bf.knnMatch(des1, des2, k=2)

# Apply ratio test to filter out weak matches
good_matches = []
for m, n in matches:
    if m.distance < 0.7 * n.distance:
        good_matches.append(m)

# Check if there are at least 5 good matches
if len(good_matches) >= 5:
    # Compute essential matrix from matched keypoints
    pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
    pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
    E, mask = cv2.findEssentialMat(pts1, pts2, focal=1.0, pp=(0., 0.), method=cv2.RANSAC, prob=0.999, threshold=3.0)

    # Recover relative camera pose from essential matrix
    _, R, t, mask = cv2.recoverPose(E, pts1, pts2)

    # Create a 3D point cloud from the matched keypoints
    P1 = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]])
    P2 = np.array([[R[0, 0], R[0, 1], R[0, 2], t[0]], [R[1, 0], R[1, 1], R[1, 2], t[1]], [R[2, 0], R[2, 1], R[2, 2], t[2]]])
    points4D = cv2.triangulatePoints(P1, P2, pts1, pts2).T

    # Convert 4D points to 3D points
    points3D = points4D[:, :3] / points4D[:, 3:]

    # Visualize the 3D point cloud
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D

    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    ax.scatter(points3D[:, 0], points3D[:, 1], points3D[:, 2])
    plt.show()
else:
    print("Not enough good matches to compute essential matrix")
