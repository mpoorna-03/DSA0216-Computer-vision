import cv2
import numpy as np

# Load the video file
cap = cv2.VideoCapture("shaky_video.mp4")

# Check if the video file is opened successfully
if not cap.isOpened():
    print("Error opening video file")
    exit()

# Read the first frame
ret, prev_frame = cap.read()
if not ret:
    print("Error reading first frame")
    exit()

prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)

# Pre-define transformation-store array
transforms = np.zeros((int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1, 3), np.float32)

# Loop over the frames
for i in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1):
    # Detect feature points in previous frame
    prev_pts = cv2.goodFeaturesToTrack(prev_gray, maxCorners=200, qualityLevel=0.01, minDistance=30, blockSize=3)

    # Read next frame
    ret, curr_frame = cap.read()
    if not ret:
        break

    # Convert to grayscale
    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)

    # Calculate optical flow (i.e. track feature points)
    curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_pts, None)

    # Filter only valid points
    idx = np.where(status == 1)[0]
    prev_pts = prev_pts[idx]
    curr_pts = curr_pts[idx]

    # Find transformation matrix
    T = cv2.estimateRigidTransform(prev_pts, curr_pts, False)

    # In rare cases no transform is found.
    # We'll just use the last known good transform.
    if T is None:
        T = np.eye(3, dtype=np.float32)
    else:
        T = T[:, :2].T

    # Extract translation
    dx = T[0, 2]
    dy = T[1, 2]

    # Extract rotation angle
    da = np.arctan2(T[1, 0], T[0, 0])

    # Store transformation
    transforms[i] = np.array([dx, dy, da])

    # Move to next frame
    prev_gray = curr_gray.copy()

# Create a video writer
fourcc = cv2.VideoWriter_fourcc(*'XVID')
fps = cap.get(cv2.CAP_PROP_FPS)
size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
out = cv2.VideoWriter("stabilized_video.mp4", fourcc, fps, size)

# Loop over the frames again to stabilize the video
cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
for i in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):
    ret, frame = cap.read()
    if not ret:
        break

    # Apply transformation to stabilize the frame
    T = np.eye(3, dtype=np.float32)
    T[0, 2] = transforms[i, 0]
    T[1, 2] = transforms[i, 1]
    T[0, 0] = np.cos(transforms[i, 2])
    T[0, 1] = -np.sin(transforms[i, 2])
    T[1, 0] = np.sin(transforms[i, 2])
    T[1, 1] = np.cos(transforms[i, 2])
    frame_stabilized = cv2.warpPerspective(frame, T, size)

    # Write the stabilized frame to the output video
    out.write(frame_stabilized)

# Release resources
cap.release()
out.release()
cv2.destroyAllWindows()
