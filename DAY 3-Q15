import cv2
import numpy as np

# Input video path
input_path = "C:\\Users\\poornima\\Downloads\\VIDEO .CV.mp4"
# Output video path
output_path = "stabilized_output.mp4"

# Initialize video capture and writer
cap = cv2.VideoCapture(input_path)
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
fps = cap.get(cv2.CAP_PROP_FPS)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

# Parameters for ShiTomasi corner detection
feature_params = dict(maxCorners=200, qualityLevel=0.01, minDistance=30, blockSize=3)

# Parameters for Lucas-Kanade optical flow
lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

# Read the first frame
ret, old_frame = cap.read()
if not ret:
    print("Failed to read video")
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    exit()

# Convert to grayscale
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)
# Detect initial features
old_points = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)

# Create a transformation matrix accumulator
transformation_accum = np.zeros((2, 3), np.float32)
n_frames = 0

# Process each frame
while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    new_points, status, _ = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, old_points, None, **lk_params)

    # Select good points
    good_old = old_points[status == 1]
    good_new = new_points[status == 1]

    # Estimate transformation
    m, _ = cv2.estimateAffinePartial2D(good_old, good_new)

    # Update transformation accumulator
    transformation_accum += m
    n_frames += 1

    # Apply the accumulated transformation
    frame_stabilized = cv2.warpAffine(frame, transformation_accum / n_frames, (frame_width, frame_height))

    # Write the stabilized frame
    out.write(frame_stabilized)

    # Update previous frame and points
    old_gray = frame_gray.copy()
    old_points = good_new.reshape(-1, 1, 2)

# Release resources
cap.release()
out.release()
cv2.destroyAllWindows()

print(f"Stabilized video saved as {output_path}")
